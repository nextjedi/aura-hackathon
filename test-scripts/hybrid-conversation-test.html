<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AURA Voice Conversation Test - Hybrid System</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            padding: 30px;
            text-align: center;
            max-width: 900px;
            width: 100%;
        }
        
        h1 {
            margin-bottom: 30px;
            font-size: 2.5rem;
            background: linear-gradient(45deg, #fff, #ffd700);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .voice-controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        button {
            background: linear-gradient(45deg, #667eea, #764ba2);
            border: none;
            color: white;
            padding: 12px 24px;
            font-size: 1rem;
            border-radius: 25px;
            cursor: pointer;
            transition: transform 0.3s, box-shadow 0.3s;
            min-width: 140px;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 15px rgba(0,0,0,0.3);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .status {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .conversation {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            min-height: 300px;
            max-height: 400px;
            overflow-y: auto;
            text-align: left;
        }
        
        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 8px;
        }
        
        .user-message {
            background: rgba(40, 167, 69, 0.3);
            border-left: 4px solid #28a745;
        }
        
        .aura-message {
            background: rgba(255, 193, 7, 0.3);
            border-left: 4px solid #ffc107;
        }
        
        .system-message {
            background: rgba(108, 117, 125, 0.3);
            border-left: 4px solid #6c757d;
            font-style: italic;
        }
        
        .voice-settings {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
            text-align: left;
        }
        
        .setting-group {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 15px;
        }
        
        .setting-group label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        
        .setting-group select, .setting-group input {
            width: 100%;
            padding: 8px;
            border-radius: 5px;
            border: 1px solid rgba(255, 255, 255, 0.3);
            background: rgba(0, 0, 0, 0.3);
            color: white;
        }
        
        .sound-effects {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .sound-btn {
            background: linear-gradient(45deg, #28a745, #20c997);
            min-width: 80px;
            font-size: 0.9rem;
            padding: 8px 16px;
        }
        
        .listening {
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 0.6; }
            50% { opacity: 1; }
            100% { opacity: 0.6; }
        }
        
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ AURA Voice Conversation Test</h1>
        
        <div class="voice-settings">
            <div class="setting-group">
                <label for="voiceSelect">AURA Voice:</label>
                <select id="voiceSelect">
                    <option value="JBFqnCBsd6RMkjVDRZzb">George (Warm Male)</option>
                    <option value="21m00Tcm4TlvDq8ikWAM">Rachel (Professional Female)</option>
                    <option value="AZnzlk1XvdvUeBnXmlld">Domi (Confident Female)</option>
                    <option value="EXAVITQu4vr4xnSDxMaL">Bella (Friendly Female)</option>
                </select>
            </div>
            
            <div class="setting-group">
                <label for="stabilitySlider">Voice Stability: <span id="stabilityValue">0.5</span></label>
                <input type="range" id="stabilitySlider" min="0" max="1" step="0.1" value="0.5">
            </div>
            
            <div class="setting-group">
                <label for="claritySlider">Voice Clarity: <span id="clarityValue">0.5</span></label>
                <input type="range" id="claritySlider" min="0" max="1" step="0.1" value="0.5">
            </div>
            
            <div class="setting-group">
                <label for="styleSlider">Style Exaggeration: <span id="styleValue">0.0</span></label>
                <input type="range" id="styleSlider" min="0" max="1" step="0.1" value="0.0">
            </div>
        </div>
        
        <div class="sound-effects">
            <button class="sound-btn" onclick="playSoundEffect('excited')">üòä Excited</button>
            <button class="sound-btn" onclick="playSoundEffect('thoughtful')">ü§î Thoughtful</button>
            <button class="sound-btn" onclick="playSoundEffect('encouraging')">üí™ Encouraging</button>
            <button class="sound-btn" onclick="playSoundEffect('surprised')">üòÆ Surprised</button>
        </div>
        
        <div class="voice-controls">
            <button id="startBtn" onclick="startListening()">üé§ Start Listening</button>
            <button id="stopBtn" onclick="stopListening()" disabled>‚èπÔ∏è Stop Listening</button>
            <button onclick="clearConversation()">üóëÔ∏è Clear Chat</button>
            <button onclick="testAURAVoice()">üîä Test AURA Voice</button>
        </div>
        
        <div id="status" class="status">
            Ready for voice conversation. Click "Start Listening" to begin.
        </div>
        
        <div id="conversation" class="conversation">
            <div class="system-message">
                <strong>AURA System:</strong> Voice conversation test ready. AURA will respond using ElevenLabs TTS with custom voice settings.
            </div>
        </div>
    </div>

    <script>
        // Configuration
        const ELEVENLABS_API_KEY = 'sk_5f41cb7d468ab4283695c25083cd78c053e1c6da3af6dcbc'; // From your .env
        let recognition = null;
        let isListening = false;
        let conversationHistory = [];
        
        // UI Elements
        const statusEl = document.getElementById('status');
        const conversationEl = document.getElementById('conversation');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        
        // Voice settings
        const voiceSelect = document.getElementById('voiceSelect');
        const stabilitySlider = document.getElementById('stabilitySlider');
        const claritySlider = document.getElementById('claritySlider');
        const styleSlider = document.getElementById('styleSlider');
        
        // Update slider values
        stabilitySlider.oninput = () => document.getElementById('stabilityValue').textContent = stabilitySlider.value;
        claritySlider.oninput = () => document.getElementById('clarityValue').textContent = claritySlider.value;
        styleSlider.oninput = () => document.getElementById('styleValue').textContent = styleSlider.value;
        
        // Initialize Speech Recognition
        function initializeSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                addMessage('system', 'Speech Recognition not supported. Please use Chrome, Edge, or Safari.');
                return false;
            }
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            
            recognition.onstart = () => {
                isListening = true;
                updateUI();
                addMessage('system', 'üé§ Listening... Speak now!');
            };
            
            recognition.onresult = async (event) => {
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    }
                }
                
                if (finalTranscript.trim()) {
                    addMessage('user', finalTranscript.trim());
                    await processUserInput(finalTranscript.trim());
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                addMessage('system', `‚ùå Speech error: ${event.error}`);
                stopListening();
            };
            
            recognition.onend = () => {
                isListening = false;
                updateUI();
                addMessage('system', 'üîá Stopped listening');
            };
            
            return true;
        }
        
        // Start/Stop listening
        function startListening() {
            if (recognition) {
                recognition.start();
            }
        }
        
        function stopListening() {
            if (recognition && isListening) {
                recognition.stop();
            }
        }
        
        // Process user input and generate AURA response
        async function processUserInput(userText) {
            addMessage('system', 'ü§ñ AURA is thinking...');
            
            // Simple response logic for demo
            let auraResponse = generateAURAResponse(userText);
            
            // Speak the response using ElevenLabs
            await speakWithElevenLabs(auraResponse);
            addMessage('aura', auraResponse);
        }
        
        // Generate AURA response (simple demo logic)
        function generateAURAResponse(userInput) {
            const input = userInput.toLowerCase();
            
            if (input.includes('hello') || input.includes('hi')) {
                return "Hello! I'm AURA, your personal styling assistant. I'm so excited to help you look absolutely amazing today! What kind of styling help are you looking for?";
            } else if (input.includes('dress') || input.includes('outfit')) {
                return "Great choice! Let me help you put together the perfect outfit. What's the occasion? Are you thinking casual, business, or something more formal?";
            } else if (input.includes('color')) {
                return "Colors are so important for your personal style! What's your skin tone like? I can suggest colors that will make you absolutely glow!";
            } else if (input.includes('business') || input.includes('work')) {
                return "Professional styling is my specialty! Let's create a confident, polished look that shows your expertise. Are you thinking blazer and pants, or maybe a dress?";
            } else if (input.includes('casual')) {
                return "I love casual chic! We can create something comfortable but still stylish. Think elevated basics that make you look effortlessly put-together!";
            } else {
                return "That's interesting! I'm here to help with all your styling needs. Would you like to talk about colors, outfits, or maybe get some specific clothing recommendations?";
            }
        }
        
        // Text-to-Speech using ElevenLabs
        async function speakWithElevenLabs(text, isSpecialEffect = false) {
            try {
                const voiceId = voiceSelect.value;
                const stability = parseFloat(stabilitySlider.value);
                const clarity = parseFloat(claritySlider.value);
                const style = parseFloat(styleSlider.value);
                
                addMessage('system', `üîä Speaking with voice settings: Stability ${stability}, Clarity ${clarity}, Style ${style}`);
                
                const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                    method: 'POST',
                    headers: {
                        'Accept': 'audio/mpeg',
                        'Content-Type': 'application/json',
                        'xi-api-key': ELEVENLABS_API_KEY
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: 'eleven_multilingual_v2',
                        voice_settings: {
                            stability: stability,
                            similarity_boost: clarity,
                            style: style,
                            use_speaker_boost: true
                        }
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`ElevenLabs API error: ${response.status} ${response.statusText}`);
                }
                
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.onplay = () => {
                    statusEl.innerHTML = 'üîä AURA is speaking...';
                };
                
                audio.onended = () => {
                    statusEl.innerHTML = 'Ready for next input';
                    URL.revokeObjectURL(audioUrl);
                };
                
                await audio.play();
                
            } catch (error) {
                console.error('ElevenLabs TTS error:', error);
                addMessage('system', `‚ùå TTS Error: ${error.message}`);
            }
        }
        
        // Sound effects with different voice settings
        async function playSoundEffect(emotion) {
            const effects = {
                excited: {
                    text: "Oh my gosh, yes! That's going to look absolutely amazing on you! I'm so excited!",
                    stability: 0.3,
                    clarity: 0.8,
                    style: 0.8
                },
                thoughtful: {
                    text: "Hmm, let me think about this... I want to make sure we get this just right for you.",
                    stability: 0.8,
                    clarity: 0.6,
                    style: 0.2
                },
                encouraging: {
                    text: "You're going to look incredible! Trust me on this - this style is perfect for you!",
                    stability: 0.4,
                    clarity: 0.9,
                    style: 0.6
                },
                surprised: {
                    text: "Wow! What an interesting choice! I love how bold and creative you're being!",
                    stability: 0.2,
                    clarity: 0.8,
                    style: 0.9
                }
            };
            
            const effect = effects[emotion];
            
            // Temporarily update sliders
            const originalSettings = {
                stability: stabilitySlider.value,
                clarity: claritySlider.value,
                style: styleSlider.value
            };
            
            stabilitySlider.value = effect.stability;
            claritySlider.value = effect.clarity;
            styleSlider.value = effect.style;
            
            // Update displays
            document.getElementById('stabilityValue').textContent = effect.stability;
            document.getElementById('clarityValue').textContent = effect.clarity;
            document.getElementById('styleValue').textContent = effect.style;
            
            await speakWithElevenLabs(effect.text, true);
            
            // Restore original settings
            setTimeout(() => {
                stabilitySlider.value = originalSettings.stability;
                claritySlider.value = originalSettings.clarity;
                styleSlider.value = originalSettings.style;
                
                document.getElementById('stabilityValue').textContent = originalSettings.stability;
                document.getElementById('clarityValue').textContent = originalSettings.clarity;
                document.getElementById('styleValue').textContent = originalSettings.style;
            }, 2000);
        }
        
        // Test AURA voice
        async function testAURAVoice() {
            const testText = "Hi there! I'm AURA, your AI styling assistant. I can't wait to help you discover your perfect style and feel absolutely confident in every outfit!";
            await speakWithElevenLabs(testText);
        }
        
        // UI functions
        function updateUI() {
            if (isListening) {
                statusEl.className = 'status listening';
                statusEl.innerHTML = 'üé§ Listening... Speak to AURA now!';
                startBtn.disabled = true;
                stopBtn.disabled = false;
            } else {
                statusEl.className = 'status';
                statusEl.innerHTML = 'Ready for voice conversation';
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        }
        
        function addMessage(type, content) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}-message`;
            
            const timestamp = new Date().toLocaleTimeString();
            let prefix = '';
            
            switch (type) {
                case 'user':
                    prefix = 'üë§ You';
                    break;
                case 'aura':
                    prefix = 'ü§ñ AURA';
                    break;
                case 'system':
                    prefix = '‚öôÔ∏è System';
                    break;
            }
            
            messageDiv.innerHTML = `<strong>${prefix}</strong> [${timestamp}]: ${content}`;
            conversationEl.appendChild(messageDiv);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }
        
        function clearConversation() {
            conversationEl.innerHTML = '<div class="system-message"><strong>AURA System:</strong> Conversation cleared. Ready for new voice interaction.</div>';
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üé§ AURA Voice Conversation Test Initialized');
            if (initializeSpeechRecognition()) {
                console.log('‚úÖ Speech Recognition ready');
                addMessage('system', '‚úÖ Voice system ready! Start talking to AURA.');
            } else {
                console.log('‚ùå Speech Recognition not available');
            }
        });
    </script>
</body>
</html>